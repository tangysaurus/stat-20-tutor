{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "NEO_PASSWORD = os.getenv(\"NEO_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ed8455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaden\\AppData\\Local\\Temp\\ipykernel_8472\\2100271186.py:2: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(\n"
     ]
    }
   ],
   "source": [
    "# Initialize knowledge graph database\n",
    "graph = Neo4jGraph(\n",
    "    url = \"neo4j+s://841b6bc1.databases.neo4j.io\",\n",
    "    username = \"neo4j\",\n",
    "    password = NEO_PASSWORD,\n",
    "    refresh_schema = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6567cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove extra new lines and whitespace\"\"\"\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_link(text):\n",
    "    \"\"\"Get relative link\"\"\"\n",
    "    text = re.search(r\"[^./].*\", text).group(0)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b121d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def scrape():\n",
    "    \"\"\"Web scrape Stat 20 lecture notes by retrieving content and next page links\"\"\"\n",
    "    rel_url = \"https://stat20.berkeley.edu/summer-2025/\"\n",
    "    url = \"https://stat20.berkeley.edu/summer-2025/1-questions-and-data/01-understanding-the-world/notes.html\" \n",
    "    content = \"lecture content\"\n",
    "    documents = []\n",
    "\n",
    "    # Iterate until there is no next page\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        html_content = response.content\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        main = soup.find(\"main\", id = \"quarto-document-content\")\n",
    "        header = soup.find(\"header\", id =\"quarto-header\")\n",
    "\n",
    "        if main:  \n",
    "            content = clean_text(main.get_text())\n",
    "\n",
    "        if header:\n",
    "            title = header.find(\"h1\", class_ = \"quarto-secondary-nav-title no-breadcrumbs\").get_text()\n",
    "\n",
    "        if content:\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content = content,\n",
    "                    metadata = {\n",
    "                        \"url\": url,\n",
    "                        \"title\": title\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "        next_page = soup.find(\"div\", class_ = \"nav-page nav-page-next\")\n",
    "        if next_page:\n",
    "            url = rel_url + clean_link(next_page.find(\"a\", href = True)[\"href\"])\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163ff939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt\n",
    "system_prompt = (\n",
    "    \"# Knowledge Graph Instructions for GPT-4\\n\"\n",
    "    \"## 1. Overview\\n\"\n",
    "    \"You are a top-tier algorithm designed for extracting information in structured \"\n",
    "    \"formats to build a knowledge graph for an educational learning platform.\\n\"\n",
    "    \"Try to capture as much information from the text as possible without \"\n",
    "    \"sacrificing accuracy. Do not add any information that is not explicitly \"\n",
    "    \"mentioned in the text.\\n\"\n",
    "    \"- **Nodes** represent entities and concepts.\\n\"\n",
    "    \"- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\n\"\n",
    "    \"helpful for a student who is reviewing for an exam.\\n\"\n",
    "    \"## 2. Labeling Nodes\\n\"\n",
    "    \"- **Consistency**: Ensure you use available types for node labels.\\n\"\n",
    "    \"Ensure you use basic or elementary types for node labels.\\n\"\n",
    "    \"- For example, when you identify an entity representing a person, \"\n",
    "    \"always label it as **'person'**. Avoid using more specific terms \"\n",
    "    \"like 'mathematician' or 'scientist'.\"\n",
    "    \"- **Node IDs**: Never utilize integers as node IDs. Node IDs should be \"\n",
    "    \"names or human-readable identifiers found in the text.\\n\"\n",
    "    \"- **Relationships** represent connections between entities or concepts.\\n\"\n",
    "    \"Ensure consistency and generality in relationship types when constructing \"\n",
    "    \"knowledge graphs. Instead of using specific and momentary types \"\n",
    "    \"such as 'BECAME_PROFESSOR', use more general and timeless relationship types \"\n",
    "    \"like 'PROFESSOR'. Make sure to use general and timeless relationship types!\\n\"\n",
    "    \"## 3. Coreference Resolution\\n\"\n",
    "    \"- **Maintain Entity Consistency**: When extracting entities, it's vital to \"\n",
    "    \"ensure consistency.\\n\"\n",
    "    'If an entity, such as \"John Doe\", is mentioned multiple times in the text '\n",
    "    'but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),'\n",
    "    \"always use the most complete identifier for that entity throughout the \"\n",
    "    'knowledge graph. In this example, use \"John Doe\" as the entity ID.\\n'\n",
    "    \"Remember, the knowledge graph should be coherent and easily understandable, \"\n",
    "    \"so maintaining consistency in entity references is crucial.\\n\"\n",
    "    \"## 4. Strict Compliance\\n\"\n",
    "    \"Adhere to the rules strictly. Non-compliance will result in termination.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25cb0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(subject: str = \"\") -> ChatPromptTemplate:\n",
    "    \"\"\"Define prompt template based on subject and user input\"\"\"\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Ensure that the entities and concepts extracted are relevant material with respect to the following subject: \" + subject + \". They should not be teachers, course names, syllabus, or miscellaneous references.\"\n",
    "                \"Tip: Make sure to answer in the correct format and do \"\n",
    "                \"not include any explanations. \"\n",
    "                \"Use the given format to extract information from the \"\n",
    "                \"following input: {input}\"\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da1ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize llm and knowledge graph database\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider = \"openai\")\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm = llm, \n",
    "    allowed_nodes = [\"MathTheorem\", \"MathConcept\"],\n",
    "    allowed_relationships = [\"Prerequisite\", \"Inclusion\"],\n",
    "    node_properties = [\"definition\"],\n",
    "    prompt = get_prompt(\"statistics\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f728b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b2f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Types Of Claims', type='Mathconcept', properties={}), Node(id='Summary', type='Mathconcept', properties={}), Node(id='Generalization', type='Mathconcept', properties={}), Node(id='Causal Claim', type='Mathconcept', properties={}), Node(id='Prediction', type='Mathconcept', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Types Of Claims', type='Mathconcept', properties={}), target=Node(id='Summary', type='Mathconcept', properties={}), type='INCLUSION', properties={}), Relationship(source=Node(id='Types Of Claims', type='Mathconcept', properties={}), target=Node(id='Generalization', type='Mathconcept', properties={}), type='INCLUSION', properties={}), Relationship(source=Node(id='Types Of Claims', type='Mathconcept', properties={}), target=Node(id='Causal Claim', type='Mathconcept', properties={}), type='INCLUSION', properties={}), Relationship(source=Node(id='Types Of Claims', type='Mathconcept', properties={}), target=Node(id='Prediction', type='Mathconcept', properties={}), type='INCLUSION', properties={})]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve nodes and relationships from documents\n",
    "graph_documents = await llm_transformer.aconvert_to_graph_documents([documents[0]])\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e42ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of node sources\n",
    "node_to_docs = {}\n",
    "\n",
    "for doc in graph_documents:\n",
    "    for node in doc.nodes:\n",
    "        if node.id in node_to_docs:\n",
    "            node_to_docs[node.id].append(doc.source)\n",
    "        else:\n",
    "            node_to_docs[node.id] = [doc.source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed53e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaden\\AppData\\Local\\Temp\\ipykernel_8472\\433382388.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "def get_embedding(text: str):\n",
    "    return embedder.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77663f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete existing nodes and relationships\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12da1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents to graph database, including document source\n",
    "graph.add_graph_documents(graph_documents, include_source = True, baseEntityLabel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b4bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings to each node\n",
    "for doc in graph_documents:\n",
    "    for node in doc.nodes:\n",
    "        embedding = get_embedding(node.id)\n",
    "        graph.query(\n",
    "            \"\"\"\n",
    "            MATCH (n {id: $id})\n",
    "            SET n.embedding = $embedding\n",
    "            \"\"\",\n",
    "            params={\"id\": node.id, \"embedding\": embedding}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce06b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#F170]  _: <CONNECTION> error: Failed to read from defunct connection ResolvedIPv4Address(('34.28.184.63', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687))): ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 0.941912047534422s (Unable to retrieve routing information)\n",
      "[#F172]  _: <CONNECTION> error: Failed to read from defunct connection IPv4Address(('si-841b6bc1-3008.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687))): ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\n",
      "Transaction failed and will be retried in 1.673323521287367s (Failed to read from defunct connection IPv4Address(('si-841b6bc1-3008.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add vector indices on nodes\n",
    "graph.query(\n",
    "    \"\"\"\n",
    "    CREATE VECTOR INDEX $name IF NOT EXISTS\n",
    "    FOR (m:Mathconcept)\n",
    "    ON m.embedding\n",
    "    OPTIONS { indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "    }}\n",
    "    \"\"\", params = {\"name\": \"mathconcept-embedding\"}\n",
    ")\n",
    "\n",
    "graph.query(\n",
    "    \"\"\"\n",
    "    CREATE VECTOR INDEX $name IF NOT EXISTS\n",
    "    FOR (m:Maththeorem)\n",
    "    ON m.embedding\n",
    "    OPTIONS { indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "    }}\n",
    "    \"\"\", params = {\"name\": \"maththeorem-embedding\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d0008",
   "metadata": {},
   "source": [
    "### Workflow: retrieve concept, find all prerequisites and create a roadmap to learn concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f66911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(object_type: str, name: str):\n",
    "    \"\"\"Get node that matches concept\"\"\"\n",
    "    query_embedding = get_embedding(concept)\n",
    "    return graph.query(\n",
    "        \"\"\"\n",
    "        WITH $embedding AS embedding\n",
    "        CALL db.index.vector.queryNodes($name, 5, embedding)\n",
    "        RETURN node.id, score\n",
    "        \"\"\", \n",
    "        params={\"embedding\": query_embedding, \"name\": \"mathconcept-embedding\" if object_type == \"concept\" else \"maththeorem-embedding\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf10d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to exclude cycles!\n",
    "def get_paths(node_id: str) -> list:\n",
    "    \"\"\"Get all paths that end at a given node\"\"\"\n",
    "    return graph.query(\n",
    "        f\"\"\"\n",
    "        MATCH path = (start)-[:PREREQUISITE|INCLUSION|MENTIONS*]->(end {{id: '{node_id}'}})\n",
    "        RETURN path\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_explanation(node_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Construct an explanation for the concept associated\n",
    "    with the given node using that node's source document\n",
    "    \"\"\"\n",
    "    source_doc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b2dd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_path(path: list) -> tuple[tuple]:\n",
    "    \"\"\"\n",
    "    Converts path list into a list of tuples of form (source node, target node, relationship)\n",
    "    e.g. [{\"id\" : \"Distribution\"}, \"INCLUSION\", {\"id\" : \"Spread\"}] -> [(\"Distribution\", \"Spread\", \"INCLUSION\")]\n",
    "    \"\"\"\n",
    "    transformed_path = []\n",
    "    i = 0\n",
    "    for i in range(0, len(path) - 2, 2):\n",
    "        transformed_path.append((path[i][\"id\"], path[i + 2][\"id\"], path[i + 1]))\n",
    "    return tuple(transformed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ec15848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subpaths(path: tuple[tuple]) -> set[tuple[tuple]]:\n",
    "    \"\"\"Get all subpaths of a path\"\"\"\n",
    "    subpaths = set()\n",
    "    for i in range(len(path)):\n",
    "        cur = [path[i]]\n",
    "        subpaths.add((path[i],))\n",
    "        for j in range(i + 1, len(path)):\n",
    "            cur.append(path[j])\n",
    "            subpaths.add(tuple(cur))\n",
    "    return subpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a92be086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subpath(path: tuple[tuple], sub_paths: set[tuple[tuple]]) -> bool:\n",
    "    \"\"\"Returns true if path is a subpath\"\"\"\n",
    "    return path in sub_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "94235c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subpaths(paths: list[dict]) -> list[tuple]:\n",
    "    \"\"\"Removes all subpaths from a list of paths\"\"\"\n",
    "    # Normalize paths\n",
    "    paths = map(normalize_path, tuple(tuple(path[\"path\"]) for path in paths))\n",
    "    paths = tuple(paths)\n",
    "\n",
    "    # Sort based on path length in descending order\n",
    "    sorted_paths = tuple(sorted(paths, key = len, reverse = True))\n",
    "    sub_paths = set()\n",
    "    filtered_paths = []\n",
    "\n",
    "    # For each path, check if it is a subpath\n",
    "    for path in sorted_paths:\n",
    "        if not is_subpath(path, sub_paths):\n",
    "            # add path to res if not subpath\n",
    "            filtered_paths.append(path)\n",
    "            # update subpaths\n",
    "            sub_paths.update(get_subpaths(path))\n",
    "\n",
    "    return filtered_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d5cef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Summarycharacteristics', 'Distributioncharacteristics', 'INCLUSION'),\n",
       "  ('Distributioncharacteristics', 'Spread', 'INCLUSION'))]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [{'path': [{'id': 'Distributioncharacteristics'},\n",
    "   'INCLUSION',\n",
    "   {'id': 'Spread'}]},\n",
    " {'path': [{'id': 'Summarycharacteristics'},\n",
    "   'INCLUSION',\n",
    "   {'id': 'Distributioncharacteristics'},\n",
    "   'INCLUSION',\n",
    "   {'id': 'Spread'}]}]\n",
    "remove_subpaths(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28983b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#D706]  _: <CONNECTION> error: Failed to read from defunct connection ResolvedIPv4Address(('34.28.184.63', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687))): ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 1.1643805523366217s (Unable to retrieve routing information)\n",
      "[#D6AE]  _: <CONNECTION> error: Failed to read from defunct connection IPv4Address(('si-841b6bc1-3008.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687))): ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\n",
      "Transaction failed and will be retried in 2.3144265490046787s (Failed to read from defunct connection IPv4Address(('si-841b6bc1-3008.production-orch-0696.neo4j.io', 7687)) (ResolvedIPv4Address(('34.28.184.63', 7687))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'path': [{'id': 'Distributioncharacteristics'},\n",
       "   'INCLUSION',\n",
       "   {'id': 'Spread'}]},\n",
       " {'path': [{'id': 'Summarycharacteristics'},\n",
       "   'INCLUSION',\n",
       "   {'id': 'Distributioncharacteristics'},\n",
       "   'INCLUSION',\n",
       "   {'id': 'Spread'}]}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_paths(\"Spread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3803926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultimate goal: given any concept I need help with, create a study plan outlining the things I need to do to learn that concept\n",
    "# Question 1: Given an arbitrary concept, how can I locate the corresponding node in the knowledge graph\n",
    "# Question 2: Given the node of a concept, how can I trace back through all its prerequisites/neighbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b969a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from tutor import KnowledgeGraph\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tools import wolfram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefdc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "NEO_PASSWORD = os.getenv(\"NEO_PASSWORD\")\n",
    "NEO_URI = os.getenv(\"NEO_URI\")\n",
    "NEO_USERNAME = os.getenv(\"NEO_USERNAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ee9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaden\\OneDrive\\Professional\\Athena\\Note Creation\\Knowledge Graph\\src\\app\\tutor.py:74: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  self.graph = Neo4jGraph(\n"
     ]
    }
   ],
   "source": [
    "knowledge_graph = KnowledgeGraph(NEO_URI, NEO_USERNAME, NEO_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aff2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec1f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([wolfram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e102fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D12D9214F0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D141943310>, root_client=<openai.OpenAI object at 0x000001D12D9215B0>, root_async_client=<openai.AsyncOpenAI object at 0x000001D12D921430>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'), max_retries=2), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wolfram', 'description': 'Queries Wolframalpha API to get information on math and science topics', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8802af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaden\\AppData\\Local\\Temp\\ipykernel_23176\\2845786025.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vector_index = knowledge_graph.create_vector_index(embeddings)\n",
    "entity_chain = knowledge_graph.create_entity_chain(llm_with_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfa3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation():\n",
    "    question = input(\"Ask a question about Stat 20 (type 'q' to exit): \")\n",
    "    print(f\"Question: {question}\")\n",
    "    if question.lower() != \"q\":\n",
    "        response = knowledge_graph.ask_query(llm_with_tools, vector_index, entity_chain, question)\n",
    "        print(f\"Response: {response}\")\n",
    "        conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96cfa32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the central limit theorem?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaden\\OneDrive\\Professional\\Athena\\Note Creation\\Knowledge Graph\\src\\app\\tutor.py:199: LangChainDeprecationWarning: The function `remove_lucene_chars` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the function exists in the :meth:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :meth:`~langchain-neo4j` and import as `from :meth:`~langchain_neo4j.vectorstores.neo4j_vector import remove_lucene_chars``.\n",
      "  words = [el for el in remove_lucene_chars(input).split() if el]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 4, column: 17, offset: 131} for query: \"\\n                CALL db.index.fulltext.queryNodes('entity', $query, {limit: 2})\\n                YIELD node, score\\n                CALL {\\n                    WITH node\\n                    MATCH (node)-[r]->(neighbor)\\n                    WHERE type(r) <> 'MENTIONS'\\n                    RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n                    UNION\\n                    WITH node\\n                    MATCH (node)<-[r]-(neighbor)\\n                    WHERE type(r) <> 'MENTIONS'\\n                    RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output\\n                }\\n                RETURN DISTINCT output\\n                LIMIT 50\\n                \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The central limit theorem says: if you add up many independent observations that each have a finite mean and variance, the standardized sum (sum Xi − sum μi) / sqrt(sum σi^2) approaches a normal (bell-shaped) distribution as the sample size grows. Practically, this means sample means are approximately normal even when the original data aren’t.\n",
      "\n",
      "Do you want a quick intuition, the conditions, or a short example with a sample mean?\n",
      "Question: q\n"
     ]
    }
   ],
   "source": [
    "conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
